{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46713afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier,GradientBoostingClassifier\n",
    "import re, string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import csv\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e96755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    number_pattern = r'\\d+'\n",
    "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
    "    return without_number\n",
    "\n",
    "def lemmatizing(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
    "        tokens[i] = lemma_word\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    removed = []\n",
    "    stop_words = list(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stop_words:\n",
    "            removed.append(tokens[i])\n",
    "    return \" \".join(removed)\n",
    "\n",
    "def remove_extra_white_spaces(text):\n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    return without_sc\n",
    "\n",
    "def preprocess(text):\n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    text=remove_stopwords(text)\n",
    "    text=lemmatizing(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3272e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\RJ\\Downloads\\output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff65eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrct text from scanned docs\n",
    "\n",
    "# Define the folder containing scanned PDF documents\n",
    "folder_path = r'C:\\Users\\RJ\\Downloads\\docs'  \n",
    "\n",
    "# Create or open a CSV file to store the extracted text\n",
    "csv_file_path =  r'C:\\Users\\RJ\\Downloads\\output.csv'\n",
    "\n",
    "# Initialize a list to store the extracted text\n",
    "extracted_text_list = []\n",
    "\n",
    "# Loop through each PDF file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_file_path = os.path.join(folder_path, filename)\n",
    "        images = convert_from_path(pdf_file_path,poppler_path = r'C:\\Users\\RJ\\Downloads\\Release-23.11.0-0\\poppler-23.11.0\\Library\\bin')\n",
    "        extracted_text = \"\"\n",
    "\n",
    "# Loop through each image and perform OCR\n",
    "        for image in images:\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        cleaned_text=preprocess(extracted_text)   \n",
    "        extracted_text_list.append([filename, cleaned_text,\"Forms\"])\n",
    "        # Print or save the extracted text\n",
    "        print(cleaned_text)\n",
    "        \n",
    "\n",
    "# Write the extracted text to a CSV file\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"Filename\", \"Extracted Text\",\"Category\"])\n",
    "    csv_writer.writerows(extracted_text_list)\n",
    "\n",
    "print(f\"Text extracted from {len(extracted_text_list)} PDF documents and saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a9bc2",
   "metadata": {},
   "source": [
    "Used Pytesseract to extract the text from scanned pdf documents.Above the the code to do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a12900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qy fe form united state security exchange comm...</td>\n",
       "      <td>Forms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>form united state omb approval security exchan...</td>\n",
       "      <td>Forms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>form united state omb approval security exchan...</td>\n",
       "      <td>Forms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sea security exchange commission te eee merial...</td>\n",
       "      <td>Forms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>warex form omb approval omb number united stat...</td>\n",
       "      <td>Forms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>japanese smoking etiquette</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>would think half century would enough time com...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>find answer perhaps itãââs better begin year o...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>situation blamed hearing negative thing onesel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>feel contented sitting beside without even utt...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Extracted Text Category\n",
       "0    qy fe form united state security exchange comm...    Forms\n",
       "1    form united state omb approval security exchan...    Forms\n",
       "2    form united state omb approval security exchan...    Forms\n",
       "3    sea security exchange commission te eee merial...    Forms\n",
       "4    warex form omb approval omb number united stat...    Forms\n",
       "..                                                 ...      ...\n",
       "234                         japanese smoking etiquette   Others\n",
       "235  would think half century would enough time com...   Others\n",
       "236  find answer perhaps itãââs better begin year o...   Others\n",
       "237  situation blamed hearing negative thing onesel...      NaN\n",
       "238  feel contented sitting beside without even utt...      NaN\n",
       "\n",
       "[239 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ae7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others    127\n",
      "Forms     101\n",
      "Name: Category, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RJ\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Category'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the data and correspond class count\n",
    "x=df['Category'].value_counts()\n",
    "print(x)\n",
    "sns.barplot(x.index,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b8eadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "df.isna().sum()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe5d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Extracted Text Category  encoded_class\n",
      "0    qy fe form united state security exchange comm...    Forms              0\n",
      "1    form united state omb approval security exchan...    Forms              0\n",
      "2    form united state omb approval security exchan...    Forms              0\n",
      "3    sea security exchange commission te eee merial...    Forms              0\n",
      "4    warex form omb approval omb number united stat...    Forms              0\n",
      "..                                                 ...      ...            ...\n",
      "232  meditate impact illness life realize better gr...   Others              1\n",
      "233  white house repeatedly chosen denial men many ...   Others              1\n",
      "234                         japanese smoking etiquette   Others              1\n",
      "235  would think half century would enough time com...   Others              1\n",
      "236  find answer perhaps itãââs better begin year o...   Others              1\n",
      "\n",
      "[228 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RJ\\AppData\\Local\\Temp/ipykernel_6012/2199027553.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['encoded_class'] = label_encoder.fit_transform(df['Category'])\n"
     ]
    }
   ],
   "source": [
    " #Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding\n",
    "df['encoded_class'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Display the encoded dataset\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce1bb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extracted Text    object\n",
       "Category          object\n",
       "encoded_class      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "242c4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>encoded_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qy fe form united state security exchange comm...</td>\n",
       "      <td>Forms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>form united state omb approval security exchan...</td>\n",
       "      <td>Forms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>form united state omb approval security exchan...</td>\n",
       "      <td>Forms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sea security exchange commission te eee merial...</td>\n",
       "      <td>Forms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>warex form omb approval omb number united stat...</td>\n",
       "      <td>Forms</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>meditate impact illness life realize better gr...</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>white house repeatedly chosen denial men many ...</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>japanese smoking etiquette</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>would think half century would enough time com...</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>find answer perhaps itãââs better begin year o...</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Extracted Text Category  encoded_class\n",
       "0    qy fe form united state security exchange comm...    Forms              0\n",
       "1    form united state omb approval security exchan...    Forms              0\n",
       "2    form united state omb approval security exchan...    Forms              0\n",
       "3    sea security exchange commission te eee merial...    Forms              0\n",
       "4    warex form omb approval omb number united stat...    Forms              0\n",
       "..                                                 ...      ...            ...\n",
       "232  meditate impact illness life realize better gr...   Others              1\n",
       "233  white house repeatedly chosen denial men many ...   Others              1\n",
       "234                         japanese smoking etiquette   Others              1\n",
       "235  would think half century would enough time com...   Others              1\n",
       "236  find answer perhaps itãââs better begin year o...   Others              1\n",
       "\n",
       "[228 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f9c287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_classes(test_data,classifier):\n",
    "    test_data=preprocess(test_data)\n",
    "    test_data=remove_extra_white_spaces(test_data)\n",
    "    test_data=remove_stopwords(test_data)\n",
    "    test_data=lemmatizing(test_data)\n",
    "    tf=tfidf_vectorizer.transform([test_data])\n",
    "    classifier.predict(tf)\n",
    "    y_pred_proba = classifier.predict_proba(tf)\n",
    "    class_labels = label_encoder.classes_\n",
    "    class_probabilities = [list(zip(class_labels, probs)) for probs in y_pred_proba]\n",
    "    top_classes = [sorted(probs, key=lambda x: x[1], reverse=True)[:3] for probs in class_probabilities]\n",
    "    return (\"Top classes:\"+str(top_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "583816df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorising the text data and Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Extracted Text'], df['encoded_class'].values, test_size=0.30)\n",
    "# Vectorize text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tfidf_vectorizer.fit(df['Extracted Text'])\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2772aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Aaproach 1:Tried RandomForest Classifier\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db72d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Top classes:[[('Others', 0.98), ('Forms', 0.02)]]\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ONGC, Eicher Motors, Hindalco Industries, Maruti Suzuki and Dr Reddy's Laboratories were among the top losers on the Nifty. The gainers included Titan Company, Bajaj Finance, L&T, Bajaj Finserv and Adani Ports\"\n",
    "get_top_classes(text,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f718c823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Top classes:[[('Others', 1.0), ('Forms', 0.0)]]\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text =\"Physicists Pierre Agostini, Ferenc Krausz and Anne L’Huillier will split the 11 million Swedish kronor (about $1 million) prize, awarded for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter.\"\n",
    "get_top_classes(text,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1b721bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aaproach 2:Tried Ensemble technique by using ramdomforest,adaboot and voting classifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Create a VotingClassifier ensemble\n",
    "ensemble = VotingClassifier(estimators=[('rf', random_forest), ('adaboost', adaboost)], voting='soft')\n",
    "\n",
    "# Train the ensemble on the training data\n",
    "ensemble.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the ensemble on the test set\n",
    "y_pred = ensemble.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f347c",
   "metadata": {},
   "source": [
    "## Predicting on data from various online sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3e331e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Top three classes:[[('Others', 0.9899998700665116), ('Forms', 0.01000012993348843)]]\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ONGC, Eicher Motors, Hindalco Industries, Maruti Suzuki and Dr Reddy's Laboratories were among the top losers on the Nifty. The gainers included Titan Company, Bajaj Finance, L&T, Bajaj Finserv and Adani Ports\"\n",
    "get_top_three_classes(text,ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24ac60cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Top classes:[[('Others', 0.9949998700665116), ('Forms', 0.005000129933488431)]]\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"A global study involving 30,000 individuals from India has found a strong link between frequent consumption of ultra-processed foods (UPFs) and decreased mental wellbeing. The study revealed that those who consumed UPFs several times a day were nearly three times more likely to struggle with their mental health compared to those who rarely or never consumed these foods.\"\n",
    "get_top_classes(text,ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30cc4d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Top classes:[[('Others', 0.9949998700665116), ('Forms', 0.005000129933488431)]]\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"I am so happy that I cannot express my happiness in words.Feels like all my dreams are coming true\"\n",
    "get_top_classes(text,ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de76d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        69\n",
      "   macro avg       1.00      1.00      1.00        69\n",
      "weighted avg       1.00      1.00      1.00        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Approach 3:Tried stacking different classifiers as base models andfinal estimator as Logistic regression\n",
    "# Define multiple base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Create a Stacking Classifier with a meta-classifier (e.g., Logistic Regression)\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(class_weight='balanced'))\n",
    "\n",
    "# Train the model\n",
    "stacking_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the Stacking model\n",
    "print(classification_report(y_test, y_pred_stacking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64315f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
